{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link na zadatke](http://www.fer.unizg.hr/_download/repository/vjezba_3%5B4%5D.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "import math\n",
    "from common import *\n",
    "from sympy.abc import x, y\n",
    "from sympy import Matrix\n",
    "\n",
    "norm = np.linalg.norm\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run Lab02.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = 100 * (y - x ** 2)  ** 2 + (1 - x) ** 2\n",
    "f1_x0 = pt(-1.9, 2.0)\n",
    "f1_xmin = pt(1, 1)\n",
    "f1_min = 0\n",
    "\n",
    "f2 = (x - 4) ** 2 + 4 * (y - 2) ** 2\n",
    "f2_x0 = pt(0.1, 0.3)\n",
    "f2_xmin = pt(4, 2)\n",
    "f2_min = 0\n",
    "\n",
    "f3 = (x - 2) ** 2 + (y + 3) ** 2\n",
    "f3_x0 = pt(0, 0)\n",
    "f3_xmin = pt(2, -3)\n",
    "f3_min = 0\n",
    "\n",
    "f4 = (x - 3) ** 2 + y ** 2\n",
    "f4_x0 = pt(0, 0)\n",
    "f4_xmin = pt(3, 0)\n",
    "f4_min = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@counted\n",
    "def evalf(f, pt):\n",
    "    return sp.lambdify([(x,y)], f)(pt)\n",
    "\n",
    "@counted\n",
    "def gradient(f):\n",
    "    jacobian = Matrix([f]).jacobian((x, y))\n",
    "    return lambda pt: sp.lambdify([(x, y)], jacobian, 'numpy')(pt).reshape(-1)\n",
    "\n",
    "@counted\n",
    "def hessian(f, constraints = []):\n",
    "    return sp.lambdify([(x, y)], sp.hessian(f, [x, y], constraints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    hessian.called = 0\n",
    "    gradient.called = 0\n",
    "    evalf.called = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 400, -200])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(f1)((1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "[Sympy gradient and Hessian](https://stackoverflow.com/questions/39558515/how-to-get-the-gradient-and-hessian-sympy)\n",
    "\n",
    "Postupak treba podržavati\n",
    "dva načina rada: u prvom načinu postupak se uvijek pomiče u novu točku za čitav iznos dobivenog pomaka\n",
    "(nenormirani vektor gradijenta), dok u drugom načinu postupak korištenjem metode zlatnog reza pronalazi\n",
    "optimalan iznos pomaka na pravcu. Postupak je potrebno zaustaviti kada euklidska norma gradijenta postane\n",
    "manja od neke zadane preciznosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/__init__.py:1: RuntimeWarning: overflow encountered in double_scalars\n",
      "  \"\"\"\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in subtract\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  inf])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(f, x0, e = 1e-6, max_iter = 1000,\n",
    "                     optimize_move_callable = lambda *x: 1.0):\n",
    "    gradient_callable = gradient(f)\n",
    "    gradient_vector = gradient_callable(x0)\n",
    "    x = np.copy(x0)\n",
    "    i = 0\n",
    "    \n",
    "    while np.linalg.norm(gradient_vector) > e and i < max_iter:\n",
    "        vector_mul = optimize_move_callable(\n",
    "            lambda d: evalf(f, x - d * gradient_vector), 0.1, e)\n",
    "        x -= vector_mul * gradient_vector\n",
    "        gradient_vector = gradient_callable(x)\n",
    "        i += 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "reset()\n",
    "gradient_descent(f1, f1_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.20875647,  1.46153288])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize_move_callable(f, d, epsilon):\n",
    "    l, r = unimodal(f, d)\n",
    "    return golden_section(f, l, r, epsilon)\n",
    "\n",
    "gradient_descent(f1, f1_x0, max_iter=10, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-Rhapson\n",
    "Postupak treba podržavati dva načina rada: u prvom načinu postupak se uvijek pomiče u novu točku za čitav\n",
    "iznos dobivenog pomaka, dok u drugom načinu postupak korištenjem metode zlatnog reza pronalazi\n",
    "optimalan iznos pomaka. Postupak je potrebno zaustaviti kada euklidska norma pomaka postane manja od\n",
    "neke zadane preciznosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newton_rhapson(f, x0, e = 1e-6, optimize_move_callable=lambda *x: 1.0, max_iter=1000):\n",
    "    x = np.copy(x0)\n",
    "\n",
    "    gradient_callable = gradient(f)\n",
    "    hessian_callable = hessian(f)\n",
    "    gradient_vector = gradient_callable(x)\n",
    "    \n",
    "    i = 0\n",
    "    while norm(gradient_vector) > e and i < max_iter:\n",
    "        i += 1\n",
    "        \n",
    "        gradient_vector = np.dot(np.linalg.inv(hessian_callable(x)), \n",
    "                                 gradient_callable(x)).reshape(-1)\n",
    "        x -= gradient_vector * optimize_move_callable(\n",
    "            lambda d: evalf(f, x - d * gradient_vector), 0.1, e)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton_rhapson(f1, f1_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Box](http://www.fer.unizg.hr/_download/repository/box.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.9989882 ,  2.00082354])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def box(f, x0, g, xd, xg, alpha=1.3, epsilon1 = 1e-6, epsilon2 = 1e-6, max_iter=1000):\n",
    "    #assert all(xd <= x0 <= xg)\n",
    "    #assert g(x0) >= 0\n",
    "    \n",
    "    xc = np.copy(x0)\n",
    "    n = len(x0)\n",
    "    h, h2 = -1, -2\n",
    "    \n",
    "    reflect = lambda xc, xh: xc + alpha * (xc - xh)\n",
    "    x = np.ones([2 * n, n])\n",
    "    \n",
    "    for t in range(2 * n):\n",
    "        for i in range(n):\n",
    "            R = np.random.randn()\n",
    "            x[t][i] = xd[i] + R * (xg[i] - xd[i])\n",
    "        while any(g(x[t]) < 0):\n",
    "            x[t] = 0.5 * (x[t] + xc)\n",
    "            xc = np.mean(x, axis=0)\n",
    "            \n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "        i += 1\n",
    "        x = sorted(x, key=lambda x: evalf(f, x))\n",
    "        \n",
    "        xc = np.mean(x[:h], axis=0)\n",
    "        xr = reflect(xc, x[h])\n",
    "        \n",
    "        for i in range(n):\n",
    "            if xr[i] < xd[i]:\n",
    "                xr[i] = xd[i]\n",
    "            elif xr[i] > xg[i]:\n",
    "                xr[i] = xg[i]\n",
    "                \n",
    "        while np.any(g(xr) < 0):\n",
    "            xr = 0.5 * (xr + xc)\n",
    "        if evalf(f, xr) > evalf(f, x[h2]):\n",
    "            xr = 0.5 * (xr + xc)\n",
    "        x[h] = xr\n",
    "        \n",
    "        if norm(x[h] - xc) <= epsilon1 or abs(evalf(f, x[h]) - evalf(f, xc)) < epsilon2:\n",
    "            break\n",
    "            \n",
    "    return xc\n",
    "\n",
    "box(f2, pt(50, 50), lambda x: x, pt(0,0), pt(10,10))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "Primijenite postupak gradijentnog spusta na funkciju 3, uz i bez određivanja optimalnog iznosa koraka. Što možete zaključiti iz rezultata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(f3, f3_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.00000004, -3.00000006])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(f3, f3_x0, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "Primijenite postupak gradijentnog spusta i Newton-Raphsonov postupak na funkcije 1 i 2 s određivanjem optimalnog iznosa koraka. Kako se Newton-Raphsonov postupak ponaša na ovim funkcijama? Ispišite broj izračuna funkcije, gradijenta i Hesseove matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1295641 ,  1.27619717])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset()\n",
    "gradient_descent(f1, f1_x0, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.99999965,  2.00000005])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset()\n",
    "gradient_descent(f2, f2_x0, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset()\n",
    "newton_rhapson(f1, f1_x0, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  2.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset()\n",
    "newton_rhapson(f2, f2_x0, optimize_move_callable=optimize_move_callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. \n",
    "Primijenite postupak po Boxu na funkcije 1 i 2 uz implicitna ograničenja: (x2-x1 >= 0), (2-x1 >= 0) i\n",
    "eksplicitna ograničenja prema kojima su sve varijable u intervalu [-100, 100]. Mijenja li se položaj\n",
    "optimuma uz nametnuta ograničenja? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01018513,  0.01018568])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box(f1, f1_x0, lambda x: np.array([x[1] - x[0], 2 - x[0]]), pt(-100, -100), pt(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.99999798,  2.0013366 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box(f2, f2_x0, lambda x: np.array([x[1] - x[0], 2 - x[0]]), pt(-100, -100), pt(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. \n",
    "Primijenite postupak transformacije u problem bez ograničenja na funkcije 1 i 2 s ograničenjima iz\n",
    "prethodnog zadatka (zanemarite eksplicitna ograničenja). Novodobiveni problem optimizacije bez\n",
    "ograničenja minimizirajte koristeći postupak Hooke-Jeeves ili postupak simpleksa po Nelderu i\n",
    "Meadu. Može li se korištenjem ovog postupka pronaći optimalno rješenje problema s ograničenjima?\n",
    "Ako ne, probajte odabrati početnu točku iz koje je moguće pronaći rješenje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "Za funkciju 4 s ograničenjima (3-x1-x2>=0), (3+1.5*x1-x2>=0) i (x2-1=0) probajte pronaći\n",
    "minimum koristeći postupak transformacije u problem bez ograničenja (također koristite HookeJeeves\n",
    "ili postupak simpleksa po Nelderu i Meadu za minimizaciju). Probajte kao početnu točku\n",
    "postaviti neku točku koja ne zadovoljava ograničenja nejednakosti (primjerice točku (5,5)) te\n",
    "pomoću postupka pronalaženja unutarnje točke odredite drugu točku koja zadovoljava ograničenja\n",
    "nejednakosti te ju iskoristite kao početnu točku za postupak minimizacije. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
